# -*- coding: utf-8 -*-
"""FuncLoss.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jsgBtSPQzcRt5SmsOm7WRXxccc-JWG54

## Tools
"""

pip install pytorch-metric-learning

"""## MNIST Dataset

### ArcFace
"""

import torch
import torchvision
import numpy as np
import pytorch_metric_learning
from pytorch_metric_learning import losses
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim

# 超参数
batch_size = 256
learning_rate = 0.01
num_epochs = 10
num_classes = 10 # MNIST有10个类别
embedding_size = 512 # 假设你的网络输出512维的嵌入向量
margin = 28.6 # 这是论文中推荐的值
scale = 64 # 这也是论文中推荐的值

# 定义一个转换函数，将灰度图像复制三次成为RGB图像
def gray_to_rgb(x):
    x = np.repeat(x, 3, axis=0)
    return x

# 定义一个数据转换器，包含上述函数和其他操作
transform = transforms.Compose([
    transforms.ToTensor(), # 将图像转换为张量，并将数值范围从[0,255]变为[0,1]
    transforms.Lambda(gray_to_rgb), # 将灰度图像转换为RGB图像
    transforms.Resize((32, 32)), # 将图像大小调整为32x32
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 将图像归一化，使其数值范围为[-1,1]
])

# 加载MNIST数据集，并应用上述转换器
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# 创建数据加载器，用于分批加载数据
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 获取预训练的ResNet-18模型
model = torchvision.models.resnet18(pretrained=False)

# 修改最后一层全连接层的输出特征数为embedding_size
num_features = model.fc.in_features # 获取全连接层的输入特征数
model.fc = nn.Linear(num_features, embedding_size) # 创建一个新的全连接层，并替换原来的全连接层

# 如果有GPU可用，则将模型移动到GPU上
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# 创建一个ArcFaceLoss对象，并传入相应的参数
loss_func = losses.ArcFaceLoss(num_classes=num_classes, embedding_size=embedding_size, margin=margin, scale=scale)

# 创建一个优化器，并将ArcFaceLoss对象的参数传递给它
optimizer = optim.SGD(list(model.parameters()) + list(loss_func.parameters()), lr=learning_rate)

# 编写训练和测试的循环，用于迭代地更新模型和损失函数的参数，并评估模型的性能
for epoch in range(num_epochs):
    # 训练阶段
    model.train() # 设置模型为训练模式
    train_loss = 0.0 # 初始化训练损失
    for data, labels in train_loader: # 遍历训练数据
        data = data.to(device) # 将图像移动到设备上
        labels = labels.to(device) # 将标签移动到设备上
        optimizer.zero_grad() # 清空梯度缓存
        embeddings = model(data) # 通过模型得到嵌入向量
        loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
        loss.backward() # 反向传播计算梯度
        optimizer.step() # 更新参数
        train_loss += loss.item() * data.size(0) # 累加训练损失

    # 测试阶段
    model.eval() # 设置模型为评估模式
    test_loss = 0.0 # 初始化测试损失
    test_acc = 0.0 # 初始化测试准确率
    with torch.no_grad(): # 不计算梯度，节省内存和时间
        for data, labels in test_loader: # 遍历测试数据
            data = data.to(device) # 将图像移动到设备上
            labels = labels.to(device) # 将标签移动到设备上
            embeddings = model(data) # 通过模型得到嵌入向量
            loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
            test_loss += loss.item() * data.size(0) # 累加测试损失
            logits = loss_func.get_logits(embeddings) # 通过损失函数得到分类的logits
            preds = torch.argmax(logits, dim=1) # 得到预测的类别
            test_acc += torch.sum(preds == labels).item() # 累加正确预测的数量

    # 打印每个epoch的结果
    train_loss /= len(train_dataset) # 计算平均训练损失
    test_loss /= len(test_dataset) # 计算平均测试损失
    test_acc /= len(test_dataset) # 计算测试准确率
    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')

# 导入matplotlib.pyplot和其他必要的库
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.manifold import TSNE

# 假设你的模型已经训练好了，并且保存在model变量中
# 假设你的测试数据集已经加载好了，并且保存在test_loader变量中

# 创建一个空的列表，用于存储嵌入向量和标签
embeddings = []
labels = []

# 遍历测试数据集，通过模型得到嵌入向量，并将它们和标签添加到列表中
with torch.no_grad(): # 不计算梯度，节省内存和时间
    for data, label in test_loader: # 遍历测试数据
        data = data.to(device) # 将图像移动到设备上
        label = label.to(device) # 将标签移动到设备上
        embedding = model(data) # 通过模型得到嵌入向量
        embeddings.append(embedding) # 将嵌入向量添加到列表中
        labels.append(label) # 将标签添加到列表中

# 将列表转换为numpy数组，并将嵌入向量的维度降为2或3，用于可视化
embeddings = torch.cat(embeddings, dim=0).cpu().numpy() # 将嵌入向量拼接起来，并转换为numpy数组
labels = torch.cat(labels, dim=0).cpu().numpy() # 将标签拼接起来，并转换为numpy数组
tsne = TSNE(n_components=3, perplexity=30, n_iter=1000) # 创建一个TSNE对象，并设置参数
embeddings_3d = tsne.fit_transform(embeddings) # 使用TSNE对象对嵌入向量进行降维，得到三维的坐标

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# 创建一个三维的图形对象，并设置标题和坐标轴标签
fig = plt.figure(figsize=(12, 9), dpi=300)
ax = fig.add_subplot(111, projection='3d')
ax.set_title('t-SNE visualization of MNIST embeddings')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

# 定义一个色系
cmap = plt.get_cmap('viridis')

# 遍历每个类别，绘制对应颜色的散点图，并添加图例
for i in range(num_classes):
    indices = labels == i  # 找到属于该类别的索引
    x = embeddings_3d[indices, 0]  # 找到对应的x坐标
    y = embeddings_3d[indices, 1]  # 找到对应的y坐标
    z = embeddings_3d[indices, 2]  # 找到对应的z坐标
    color = np.array([cmap(float(i) / num_classes)])  # 将颜色值封装为数组
    ax.scatter(x, y, z, c=color, label=str(i))  # 绘制散点图，并设置颜色和标签

# 创建一个输出小部件
output_widget = widgets.Output()

# 显示图像
with output_widget:
    display(fig)

# 创建一个控制旋转的小部件
rotation_slider = widgets.FloatSlider(min=-180, max=180, value=0, description='Rotation')

# 定义一个函数来更新图像的旋转角度
def update_rotation_angle(change):
    angle = change.new
    ax.view_init(elev=30, azim=angle)
    with output_widget:
        output_widget.clear_output(wait=True)
        display(fig)

# 将更新函数绑定到旋转小部件的值变化事件
rotation_slider.observe(update_rotation_angle, 'value')

# 创建一个垂直布局小部件来显示图像和旋转控制
vbox = widgets.VBox([output_widget, rotation_slider])

# 显示垂直布局小部件
display(vbox)

"""### CosFace"""

import torch
import torchvision
import numpy as np
import pytorch_metric_learning
from pytorch_metric_learning import losses
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim

# 超参数
batch_size = 256
learning_rate = 0.01
num_epochs = 10
num_classes = 10 # MNIST有10个类别
embedding_size = 512 # 假设你的网络输出512维的嵌入向量
margin = 28.6 # 这是论文中推荐的值
scale = 64 # 这也是论文中推荐的值

# 定义一个转换函数，将灰度图像复制三次成为RGB图像
def gray_to_rgb(x):
    x = np.repeat(x, 3, axis=0)
    return x

# 定义一个数据转换器，包含上述函数和其他操作
transform = transforms.Compose([
    transforms.ToTensor(), # 将图像转换为张量，并将数值范围从[0,255]变为[0,1]
    transforms.Lambda(gray_to_rgb), # 将灰度图像转换为RGB图像
    transforms.Resize((32, 32)), # 将图像大小调整为32x32
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 将图像归一化，使其数值范围为[-1,1]
])

# 加载MNIST数据集，并应用上述转换器
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# 创建数据加载器，用于分批加载数据
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 获取预训练的ResNet-18模型
model = torchvision.models.resnet18(pretrained=False)

# 修改最后一层全连接层的输出特征数为embedding_size
num_features = model.fc.in_features # 获取全连接层的输入特征数
model.fc = nn.Linear(num_features, embedding_size) # 创建一个新的全连接层，并替换原来的全连接层

# 如果有GPU可用，则将模型移动到GPU上
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# 创建一个CosFaceLoss对象，并传入相应的参数
loss_func = losses.CosFaceLoss(num_classes=num_classes, embedding_size=embedding_size, margin=margin, scale=scale)

# 创建一个优化器，并将CosFaceLoss对象的参数传递给它
optimizer = optim.SGD(list(model.parameters()) + list(loss_func.parameters()), lr=learning_rate)

# 编写训练和测试的循环，用于迭代地更新模型和损失函数的参数，并评估模型的性能
for epoch in range(num_epochs):
    # 训练阶段
    model.train() # 设置模型为训练模式
    train_loss = 0.0 # 初始化训练损失
    for data, labels in train_loader: # 遍历训练数据
        data = data.to(device) # 将图像移动到设备上
        labels = labels.to(device) # 将标签移动到设备上
        optimizer.zero_grad() # 清空梯度缓存
        embeddings = model(data) # 通过模型得到嵌入向量
        loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
        loss.backward() # 反向传播计算梯度
        optimizer.step() # 更新参数
        train_loss += loss.item() * data.size(0) # 累加训练损失

    # 测试阶段
    model.eval() # 设置模型为评估模式
    test_loss = 0.0 # 初始化测试损失
    test_acc = 0.0 # 初始化测试准确率
    with torch.no_grad(): # 不计算梯度，节省内存和时间
        for data, labels in test_loader: # 遍历测试数据
            data = data.to(device) # 将图像移动到设备上
            labels = labels.to(device) # 将标签移动到设备上
            embeddings = model(data) # 通过模型得到嵌入向量
            loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
            test_loss += loss.item() * data.size(0) # 累加测试损失
            logits = loss_func.get_logits(embeddings) # 通过损失函数得到分类的logits
            preds = torch.argmax(logits, dim=1) # 得到预测的类别
            test_acc += torch.sum(preds == labels).item() # 累加正确预测的数量

    # 打印每个epoch的结果
    train_loss /= len(train_dataset) # 计算平均训练损失
    test_loss /= len(test_dataset) # 计算平均测试损失
    test_acc /= len(test_dataset) # 计算测试准确率
    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')

# 导入matplotlib.pyplot和其他必要的库
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.manifold import TSNE

# 假设你的模型已经训练好了，并且保存在model变量中
# 假设你的测试数据集已经加载好了，并且保存在test_loader变量中

# 创建一个空的列表，用于存储嵌入向量和标签
embeddings = []
labels = []

# 遍历测试数据集，通过模型得到嵌入向量，并将它们和标签添加到列表中
with torch.no_grad(): # 不计算梯度，节省内存和时间
    for data, label in test_loader: # 遍历测试数据
        data = data.to(device) # 将图像移动到设备上
        label = label.to(device) # 将标签移动到设备上
        embedding = model(data) # 通过模型得到嵌入向量
        embeddings.append(embedding) # 将嵌入向量添加到列表中
        labels.append(label) # 将标签添加到列表中

# 将列表转换为numpy数组，并将嵌入向量的维度降为2或3，用于可视化
embeddings = torch.cat(embeddings, dim=0).cpu().numpy() # 将嵌入向量拼接起来，并转换为numpy数组
labels = torch.cat(labels, dim=0).cpu().numpy() # 将标签拼接起来，并转换为numpy数组
tsne = TSNE(n_components=3, perplexity=30, n_iter=1000) # 创建一个TSNE对象，并设置参数
embeddings_3d = tsne.fit_transform(embeddings) # 使用TSNE对象对嵌入向量进行降维，得到三维的坐标

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# 创建一个三维的图形对象，并设置标题和坐标轴标签
fig = plt.figure(figsize=(12, 9), dpi=300)
ax = fig.add_subplot(111, projection='3d')
ax.set_title('MNIST × CosFace')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

# 定义一个色系
cmap = plt.get_cmap('viridis')

# 遍历每个类别，绘制对应颜色的散点图，并添加图例
for i in range(num_classes):
    indices = labels == i  # 找到属于该类别的索引
    x = embeddings_3d[indices, 0]  # 找到对应的x坐标
    y = embeddings_3d[indices, 1]  # 找到对应的y坐标
    z = embeddings_3d[indices, 2]  # 找到对应的z坐标
    color = np.array([cmap(float(i) / num_classes)])  # 将颜色值封装为数组
    ax.scatter(x, y, z, c=color, label=str(i))  # 绘制散点图，并设置颜色和标签

# 创建一个输出小部件
output_widget = widgets.Output()

# 显示图像
with output_widget:
    display(fig)

# 创建一个控制旋转的小部件
rotation_slider = widgets.FloatSlider(min=-180, max=180, value=0, description='Rotation')

# 定义一个函数来更新图像的旋转角度
def update_rotation_angle(change):
    angle = change.new
    ax.view_init(elev=30, azim=angle)
    with output_widget:
        output_widget.clear_output(wait=True)
        display(fig)

# 将更新函数绑定到旋转小部件的值变化事件
rotation_slider.observe(update_rotation_angle, 'value')

# 创建一个垂直布局小部件来显示图像和旋转控制
vbox = widgets.VBox([output_widget, rotation_slider])

# 显示垂直布局小部件
display(vbox)

"""### TripletMarginLoss"""

from pytorch_metric_learning import miners
import torch
import torchvision
import numpy as np
import pytorch_metric_learning
from pytorch_metric_learning import losses
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm

# 创建一个 MultiSimilarityMiner 对象
miner = miners.MultiSimilarityMiner()


# 超参数
batch_size = 256
learning_rate = 0.01
num_epochs = 10
num_classes = 10 # MNIST有10个类别
embedding_size = 512 # 假设你的网络输出512维的嵌入向量
margin = 28.6 # 这是论文中推荐的值
scale = 64 # 这也是论文中推荐的值

# 定义一个转换函数，将灰度图像复制三次成为RGB图像
def gray_to_rgb(x):
    x = np.repeat(x, 3, axis=0)
    return x

# 定义一个数据转换器，包含上述函数和其他操作
transform = transforms.Compose([
    transforms.ToTensor(), # 将图像转换为张量，并将数值范围从[0,255]变为[0,1]
    transforms.Lambda(gray_to_rgb), # 将灰度图像转换为RGB图像
    transforms.Resize((32, 32)), # 将图像大小调整为32x32
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 将图像归一化，使其数值范围为[-1,1]
])

# 加载MNIST数据集，并应用上述转换器
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# 创建数据加载器，用于分批加载数据
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 获取预训练的ResNet-18模型
model = torchvision.models.resnet18(pretrained=False)

# 修改最后一层全连接层的输出特征数为embedding_size
num_features = model.fc.in_features # 获取全连接层的输入特征数
model.fc = nn.Sequential(
    nn.Linear(num_features, embedding_size),
    nn.ReLU(),
    nn.Linear(embedding_size, num_classes)
)

# 如果有GPU可用，则将模型移动到GPU上
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# 创建一个 TripletMarginLoss 对象
loss_func = losses.TripletMarginLoss(margin=0.05)

# 创建一个优化器，并将TripletMarginLoss对象的参数传递给它
optimizer = optim.SGD(list(model.parameters()) + list(loss_func.parameters()), lr=learning_rate)

for epoch in range(num_epochs):
    # 训练阶段
    model.train()
    train_loss = 0.0
    for data, labels in tqdm(train_loader, desc="Training"):
        data = data.to(device)
        labels = labels.to(device)
        optimizer.zero_grad()
        embeddings = model(data)
        
        # 调用 miner 得到 indices_tuple
        indices_tuple = miner(embeddings, labels)
        
        # 将 embeddings 和 indices_tuple 传入 loss_func
        loss = loss_func(embeddings, labels, indices_tuple)
        
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * data.size(0)

    # 测试阶段
    model.eval()
    test_loss = 0.0
    test_acc = 0.0
    with torch.no_grad():
        for data, labels in tqdm(test_loader, desc="Testing"):
            data = data.to(device)
            labels = labels.to(device)
            outputs = model(data) # 使用模型的输出作为预测结果
            embeddings = outputs[:, :-num_classes] # 获取嵌入向量
            
            indices_tuple = miner(embeddings, labels)
            
            loss = loss_func(embeddings, labels, indices_tuple)
            
            test_loss += loss.item() * data.size(0)
            preds = torch.argmax(outputs, dim=1) # 使用模型的输出来获取预测的类别
            test_acc += torch.sum(preds == labels).item()

    train_loss /= len(train_dataset)
    test_loss /= len(test_dataset)
    test_acc /= len(test_dataset)
    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')

# 导入matplotlib.pyplot和其他必要的库
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.manifold import TSNE

# 假设你的模型已经训练好了，并且保存在model变量中
# 假设你的测试数据集已经加载好了，并且保存在test_loader变量中

# 创建一个空的列表，用于存储嵌入向量和标签
embeddings = []
labels = []

# 遍历测试数据集，通过模型得到嵌入向量，并将它们和标签添加到列表中
with torch.no_grad(): # 不计算梯度，节省内存和时间
    for data, label in test_loader: # 遍历测试数据
        data = data.to(device) # 将图像移动到设备上
        label = label.to(device) # 将标签移动到设备上
        embedding = model(data) # 通过模型得到嵌入向量
        embeddings.append(embedding) # 将嵌入向量添加到列表中
        labels.append(label) # 将标签添加到列表中

# 将列表转换为numpy数组，并将嵌入向量的维度降为2或3，用于可视化
embeddings = torch.cat(embeddings, dim=0).cpu().numpy() # 将嵌入向量拼接起来，并转换为numpy数组
labels = torch.cat(labels, dim=0).cpu().numpy() # 将标签拼接起来，并转换为numpy数组
tsne = TSNE(n_components=3, perplexity=30, n_iter=1000) # 创建一个TSNE对象，并设置参数
embeddings_3d = tsne.fit_transform(embeddings) # 使用TSNE对象对嵌入向量进行降维，得到三维的坐标

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# 创建一个三维的图形对象，并设置标题和坐标轴标签
fig = plt.figure(figsize=(12, 9), dpi=300)
ax = fig.add_subplot(111, projection='3d')
ax.set_title('MNIST × TripletMarginLoss')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

# 定义一个色系
cmap = plt.get_cmap('viridis')

# 遍历每个类别，绘制对应颜色的散点图，并添加图例
for i in range(num_classes):
    indices = labels == i  # 找到属于该类别的索引
    x = embeddings_3d[indices, 0]  # 找到对应的x坐标
    y = embeddings_3d[indices, 1]  # 找到对应的y坐标
    z = embeddings_3d[indices, 2]  # 找到对应的z坐标
    color = np.array([cmap(float(i) / num_classes)])  # 将颜色值封装为数组
    ax.scatter(x, y, z, c=color, label=str(i))  # 绘制散点图，并设置颜色和标签

# 创建一个输出小部件
output_widget = widgets.Output()

# 显示图像
with output_widget:
    display(fig)

# 创建一个控制旋转的小部件
rotation_slider = widgets.FloatSlider(min=-180, max=180, value=0, description='Rotation')

# 定义一个函数来更新图像的旋转角度
def update_rotation_angle(change):
    angle = change.new
    ax.view_init(elev=30, azim=angle)
    with output_widget:
        output_widget.clear_output(wait=True)
        display(fig)

# 将更新函数绑定到旋转小部件的值变化事件
rotation_slider.observe(update_rotation_angle, 'value')

# 创建一个垂直布局小部件来显示图像和旋转控制
vbox = widgets.VBox([output_widget, rotation_slider])

# 显示垂直布局小部件
display(vbox)

"""## CIFAR-10 Dataset

### ArcFace
"""

import torch
import torchvision
import numpy as np
import pytorch_metric_learning
from pytorch_metric_learning import losses
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim

# 超参数
batch_size = 32
learning_rate = 0.05
num_epochs = 10
num_classes = 10 # MNIST有10个类别
embedding_size = 512 # 假设你的网络输出512维的嵌入向量
margin = 28.6 # 这是论文中推荐的值
scale = 64 # 这也是论文中推荐的值

# 定义一个数据转换器，包含上述函数和其他操作
transform = transforms.Compose([
    transforms.ToTensor(), # 将图像转换为张量，并将数值范围从[0,255]变为[0,1]
    transforms.Resize((32, 32)), # 将图像大小调整为32x32
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 将图像归一化，使其数值范围为[-1,1]
])

# 加载CIFAR10数据集，并应用上述转换器
train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

# 创建数据加载器，用于分批加载数据
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 获取预训练的ResNet-18模型
model = torchvision.models.resnet18(pretrained=False)

# 修改最后一层全连接层的输出特征数为embedding_size
num_features = model.fc.in_features # 获取全连接层的输入特征数
model.fc = nn.Linear(num_features, embedding_size) # 创建一个新的全连接层，并替换原来的全连接层

# 如果有GPU可用，则将模型移动到GPU上
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# 创建一个ArcFaceLoss对象，并传入相应的参数
loss_func = losses.ArcFaceLoss(num_classes=num_classes, embedding_size=embedding_size, margin=margin, scale=scale)

# 创建一个优化器，并将ArcFaceLoss对象的参数传递给它
optimizer = optim.SGD(list(model.parameters()) + list(loss_func.parameters()), lr=learning_rate)

# 编写训练和测试的循环，用于迭代地更新模型和损失函数的参数，并评估模型的性能
for epoch in range(num_epochs):
    # 训练阶段
    model.train() # 设置模型为训练模式
    train_loss = 0.0 # 初始化训练损失
    for data, labels in train_loader: # 遍历训练数据
        data = data.to(device) # 将图像移动到设备上
        labels = labels.to(device) # 将标签移动到设备上
        optimizer.zero_grad() # 清空梯度缓存
        embeddings = model(data) # 通过模型得到嵌入向量
        loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
        loss.backward() # 反向传播计算梯度
        optimizer.step() # 更新参数
        train_loss += loss.item() * data.size(0) # 累加训练损失

    # 测试阶段
    model.eval() # 设置模型为评估模式
    test_loss = 0.0 # 初始化测试损失
    test_acc = 0.0 # 初始化测试准确率
    with torch.no_grad(): # 不计算梯度，节省内存和时间
        for data, labels in test_loader: # 遍历测试数据
            data = data.to(device) # 将图像移动到设备上
            labels = labels.to(device) # 将标签移动到设备上
            embeddings = model(data) # 通过模型得到嵌入向量
            loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
            test_loss += loss.item() * data.size(0) # 累加测试损失
            logits = loss_func.get_logits(embeddings) # 通过损失函数得到分类的logits
            preds = torch.argmax(logits, dim=1) # 得到预测的类别
            test_acc += torch.sum(preds == labels).item() # 累加正确预测的数量

    # 打印每个epoch的结果
    train_loss /= len(train_dataset) # 计算平均训练损失
    test_loss /= len(test_dataset) # 计算平均测试损失
    test_acc /= len(test_dataset) # 计算测试准确率
    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')

# 导入matplotlib.pyplot和其他必要的库
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.manifold import TSNE

# 假设你的模型已经训练好了，并且保存在model变量中
# 假设你的测试数据集已经加载好了，并且保存在test_loader变量中

# 创建一个空的列表，用于存储嵌入向量和标签
embeddings = []
labels = []

# 遍历测试数据集，通过模型得到嵌入向量，并将它们和标签添加到列表中
with torch.no_grad(): # 不计算梯度，节省内存和时间
    for data, label in test_loader: # 遍历测试数据
        data = data.to(device) # 将图像移动到设备上
        label = label.to(device) # 将标签移动到设备上
        embedding = model(data) # 通过模型得到嵌入向量
        embeddings.append(embedding) # 将嵌入向量添加到列表中
        labels.append(label) # 将标签添加到列表中

# 将列表转换为numpy数组，并将嵌入向量的维度降为2或3，用于可视化
embeddings = torch.cat(embeddings, dim=0).cpu().numpy() # 将嵌入向量拼接起来，并转换为numpy数组
labels = torch.cat(labels, dim=0).cpu().numpy() # 将标签拼接起来，并转换为numpy数组
tsne = TSNE(n_components=3, perplexity=30, n_iter=1000) # 创建一个TSNE对象，并设置参数
embeddings_3d = tsne.fit_transform(embeddings) # 使用TSNE对象对嵌入向量进行降维，得到三维的坐标

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# 创建一个三维的图形对象，并设置标题和坐标轴标签
fig = plt.figure(figsize=(12, 9), dpi=300)
ax = fig.add_subplot(111, projection='3d')
ax.set_title('CIFAR10 × ArcFace')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

# 定义一个色系
cmap = plt.get_cmap('viridis')

# 遍历每个类别，绘制对应颜色的散点图，并添加图例
for i in range(num_classes):
    indices = labels == i  # 找到属于该类别的索引
    x = embeddings_3d[indices, 0]  # 找到对应的x坐标
    y = embeddings_3d[indices, 1]  # 找到对应的y坐标
    z = embeddings_3d[indices, 2]  # 找到对应的z坐标
    color = np.array([cmap(float(i) / num_classes)])  # 将颜色值封装为数组
    ax.scatter(x, y, z, c=color, label=str(i))  # 绘制散点图，并设置颜色和标签

# 创建一个输出小部件
output_widget = widgets.Output()

# 显示图像
with output_widget:
    display(fig)

# 创建一个控制旋转的小部件
rotation_slider = widgets.FloatSlider(min=-180, max=180, value=0, description='Rotation')

# 定义一个函数来更新图像的旋转角度
def update_rotation_angle(change):
    angle = change.new
    ax.view_init(elev=30, azim=angle)
    with output_widget:
        output_widget.clear_output(wait=True)
        display(fig)

# 将更新函数绑定到旋转小部件的值变化事件
rotation_slider.observe(update_rotation_angle, 'value')

# 创建一个垂直布局小部件来显示图像和旋转控制
vbox = widgets.VBox([output_widget, rotation_slider])

# 显示垂直布局小部件
display(vbox)

"""### CosFace"""

import torch
import torchvision
import numpy as np
import pytorch_metric_learning
from pytorch_metric_learning import losses
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim

# 超参数
batch_size = 32
learning_rate = 0.05
num_epochs = 10
num_classes = 10 # MNIST有10个类别
embedding_size = 512 # 假设你的网络输出512维的嵌入向量
margin = 28.6 # 这是论文中推荐的值
scale = 64 # 这也是论文中推荐的值

# 定义一个数据转换器，包含上述函数和其他操作
transform = transforms.Compose([
    transforms.ToTensor(), # 将图像转换为张量，并将数值范围从[0,255]变为[0,1]
    transforms.Resize((32, 32)), # 将图像大小调整为32x32
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 将图像归一化，使其数值范围为[-1,1]
])

# 加载CIFAR10数据集，并应用上述转换器
train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

# 创建数据加载器，用于分批加载数据
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 获取预训练的ResNet-18模型
model = torchvision.models.resnet18(pretrained=False)

# 修改最后一层全连接层的输出特征数为embedding_size
num_features = model.fc.in_features # 获取全连接层的输入特征数
model.fc = nn.Linear(num_features, embedding_size) # 创建一个新的全连接层，并替换原来的全连接层

# 如果有GPU可用，则将模型移动到GPU上
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# 创建一个CosFaceLoss对象，并传入相应的参数
loss_func = losses.CosFaceLoss(num_classes=num_classes, embedding_size=embedding_size, margin=margin, scale=scale)

# 创建一个优化器，并将CosFaceLoss对象的参数传递给它
optimizer = optim.SGD(list(model.parameters()) + list(loss_func.parameters()), lr=learning_rate)

# 编写训练和测试的循环，用于迭代地更新模型和损失函数的参数，并评估模型的性能
for epoch in range(num_epochs):
    # 训练阶段
    model.train() # 设置模型为训练模式
    train_loss = 0.0 # 初始化训练损失
    for data, labels in train_loader: # 遍历训练数据
        data = data.to(device) # 将图像移动到设备上
        labels = labels.to(device) # 将标签移动到设备上
        optimizer.zero_grad() # 清空梯度缓存
        embeddings = model(data) # 通过模型得到嵌入向量
        loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
        loss.backward() # 反向传播计算梯度
        optimizer.step() # 更新参数
        train_loss += loss.item() * data.size(0) # 累加训练损失

    # 测试阶段
    model.eval() # 设置模型为评估模式
    test_loss = 0.0 # 初始化测试损失
    test_acc = 0.0 # 初始化测试准确率
    with torch.no_grad(): # 不计算梯度，节省内存和时间
        for data, labels in test_loader: # 遍历测试数据
            data = data.to(device) # 将图像移动到设备上
            labels = labels.to(device) # 将标签移动到设备上
            embeddings = model(data) # 通过模型得到嵌入向量
            loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
            test_loss += loss.item() * data.size(0) # 累加测试损失
            logits = loss_func.get_logits(embeddings) # 通过损失函数得到分类的logits
            preds = torch.argmax(logits, dim=1) # 得到预测的类别
            test_acc += torch.sum(preds == labels).item() # 累加正确预测的数量

    # 打印每个epoch的结果
    train_loss /= len(train_dataset) # 计算平均训练损失
    test_loss /= len(test_dataset) # 计算平均测试损失
    test_acc /= len(test_dataset) # 计算测试准确率
    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')

# 导入matplotlib.pyplot和其他必要的库
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.manifold import TSNE

# 假设你的模型已经训练好了，并且保存在model变量中
# 假设你的测试数据集已经加载好了，并且保存在test_loader变量中

# 创建一个空的列表，用于存储嵌入向量和标签
embeddings = []
labels = []

# 遍历测试数据集，通过模型得到嵌入向量，并将它们和标签添加到列表中
with torch.no_grad(): # 不计算梯度，节省内存和时间
    for data, label in test_loader: # 遍历测试数据
        data = data.to(device) # 将图像移动到设备上
        label = label.to(device) # 将标签移动到设备上
        embedding = model(data) # 通过模型得到嵌入向量
        embeddings.append(embedding) # 将嵌入向量添加到列表中
        labels.append(label) # 将标签添加到列表中

# 将列表转换为numpy数组，并将嵌入向量的维度降为2或3，用于可视化
embeddings = torch.cat(embeddings, dim=0).cpu().numpy() # 将嵌入向量拼接起来，并转换为numpy数组
labels = torch.cat(labels, dim=0).cpu().numpy() # 将标签拼接起来，并转换为numpy数组
tsne = TSNE(n_components=3, perplexity=30, n_iter=1000) # 创建一个TSNE对象，并设置参数
embeddings_3d = tsne.fit_transform(embeddings) # 使用TSNE对象对嵌入向量进行降维，得到三维的坐标

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# 创建一个三维的图形对象，并设置标题和坐标轴标签
fig = plt.figure(figsize=(12, 9), dpi=300)
ax = fig.add_subplot(111, projection='3d')
ax.set_title('CIFAR10 × CosFace')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

# 定义一个色系
cmap = plt.get_cmap('viridis')

# 遍历每个类别，绘制对应颜色的散点图，并添加图例
for i in range(num_classes):
    indices = labels == i  # 找到属于该类别的索引
    x = embeddings_3d[indices, 0]  # 找到对应的x坐标
    y = embeddings_3d[indices, 1]  # 找到对应的y坐标
    z = embeddings_3d[indices, 2]  # 找到对应的z坐标
    color = np.array([cmap(float(i) / num_classes)])  # 将颜色值封装为数组
    ax.scatter(x, y, z, c=color, label=str(i))  # 绘制散点图，并设置颜色和标签

# 创建一个输出小部件
output_widget = widgets.Output()

# 显示图像
with output_widget:
    display(fig)

# 创建一个控制旋转的小部件
rotation_slider = widgets.FloatSlider(min=-180, max=180, value=0, description='Rotation')

# 定义一个函数来更新图像的旋转角度
def update_rotation_angle(change):
    angle = change.new
    ax.view_init(elev=30, azim=angle)
    with output_widget:
        output_widget.clear_output(wait=True)
        display(fig)

# 将更新函数绑定到旋转小部件的值变化事件
rotation_slider.observe(update_rotation_angle, 'value')

# 创建一个垂直布局小部件来显示图像和旋转控制
vbox = widgets.VBox([output_widget, rotation_slider])

# 显示垂直布局小部件
display(vbox)

"""### TripletMarginLoss"""

from pytorch_metric_learning import miners
import torch
import torchvision
import numpy as np
import pytorch_metric_learning
from pytorch_metric_learning import losses
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm

# 创建一个 MultiSimilarityMiner 对象
miner = miners.MultiSimilarityMiner()


# 超参数
batch_size = 32
learning_rate = 0.05
num_epochs = 10
num_classes = 10 # MNIST有10个类别
embedding_size = 512 # 假设你的网络输出512维的嵌入向量
margin = 28.6 # 这是论文中推荐的值
scale = 64 # 这也是论文中推荐的值

# 定义一个数据转换器，包含上述函数和其他操作
transform = transforms.Compose([
    transforms.ToTensor(), # 将图像转换为张量，并将数值范围从[0,255]变为[0,1]
    transforms.Resize((32, 32)), # 将图像大小调整为32x32
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 将图像归一化，使其数值范围为[-1,1]
])

# 加载CIFAR10数据集，并应用上述转换器
train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

# 创建数据加载器，用于分批加载数据
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 获取预训练的ResNet-18模型
model = torchvision.models.resnet18(pretrained=False)

# 修改最后一层全连接层的输出特征数为embedding_size
num_features = model.fc.in_features # 获取全连接层的输入特征数
model.fc = nn.Sequential(
    nn.Linear(num_features, embedding_size),
    nn.ReLU(),
    nn.Linear(embedding_size, num_classes)
)

# 如果有GPU可用，则将模型移动到GPU上
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# 创建一个 TripletMarginLoss 对象
loss_func = losses.TripletMarginLoss(margin=0.05)

# 创建一个优化器，并将TripletMarginLoss对象的参数传递给它
optimizer = optim.SGD(list(model.parameters()) + list(loss_func.parameters()), lr=learning_rate)

for epoch in range(num_epochs):
    # 训练阶段
    model.train()
    train_loss = 0.0
    for data, labels in tqdm(train_loader, desc="Training"):
        data = data.to(device)
        labels = labels.to(device)
        optimizer.zero_grad()
        embeddings = model(data)
        
        # 调用 miner 得到 indices_tuple
        indices_tuple = miner(embeddings, labels)
        
        # 将 embeddings 和 indices_tuple 传入 loss_func
        loss = loss_func(embeddings, labels, indices_tuple)
        
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * data.size(0)

    # 测试阶段
    model.eval()
    test_loss = 0.0
    test_acc = 0.0
    with torch.no_grad():
        for data, labels in tqdm(test_loader, desc="Testing"):
            data = data.to(device)
            labels = labels.to(device)
            outputs = model(data) # 使用模型的输出作为预测结果
            embeddings = outputs[:, :-num_classes] # 获取嵌入向量
            
            indices_tuple = miner(embeddings, labels)
            
            loss = loss_func(embeddings, labels, indices_tuple)
            
            test_loss += loss.item() * data.size(0)
            preds = torch.argmax(outputs, dim=1) # 使用模型的输出来获取预测的类别
            test_acc += torch.sum(preds == labels).item()

    train_loss /= len(train_dataset)
    test_loss /= len(test_dataset)
    test_acc /= len(test_dataset)
    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')

# 导入matplotlib.pyplot和其他必要的库
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.manifold import TSNE

# 假设你的模型已经训练好了，并且保存在model变量中
# 假设你的测试数据集已经加载好了，并且保存在test_loader变量中

# 创建一个空的列表，用于存储嵌入向量和标签
embeddings = []
labels = []

# 遍历测试数据集，通过模型得到嵌入向量，并将它们和标签添加到列表中
with torch.no_grad(): # 不计算梯度，节省内存和时间
    for data, label in test_loader: # 遍历测试数据
        data = data.to(device) # 将图像移动到设备上
        label = label.to(device) # 将标签移动到设备上
        embedding = model(data) # 通过模型得到嵌入向量
        embeddings.append(embedding) # 将嵌入向量添加到列表中
        labels.append(label) # 将标签添加到列表中

# 将列表转换为numpy数组，并将嵌入向量的维度降为2或3，用于可视化
embeddings = torch.cat(embeddings, dim=0).cpu().numpy() # 将嵌入向量拼接起来，并转换为numpy数组
labels = torch.cat(labels, dim=0).cpu().numpy() # 将标签拼接起来，并转换为numpy数组
tsne = TSNE(n_components=3, perplexity=30, n_iter=1000) # 创建一个TSNE对象，并设置参数
embeddings_3d = tsne.fit_transform(embeddings) # 使用TSNE对象对嵌入向量进行降维，得到三维的坐标

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# 创建一个三维的图形对象，并设置标题和坐标轴标签
fig = plt.figure(figsize=(12, 9), dpi=300)
ax = fig.add_subplot(111, projection='3d')
ax.set_title('CIFAR10 × TripletMarginLoss')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

# 定义一个色系
cmap = plt.get_cmap('viridis')

# 遍历每个类别，绘制对应颜色的散点图，并添加图例
for i in range(num_classes):
    indices = labels == i  # 找到属于该类别的索引
    x = embeddings_3d[indices, 0]  # 找到对应的x坐标
    y = embeddings_3d[indices, 1]  # 找到对应的y坐标
    z = embeddings_3d[indices, 2]  # 找到对应的z坐标
    color = np.array([cmap(float(i) / num_classes)])  # 将颜色值封装为数组
    ax.scatter(x, y, z, c=color, label=str(i))  # 绘制散点图，并设置颜色和标签

# 创建一个输出小部件
output_widget = widgets.Output()

# 显示图像
with output_widget:
    display(fig)

# 创建一个控制旋转的小部件
rotation_slider = widgets.FloatSlider(min=-180, max=180, value=0, description='Rotation')

# 定义一个函数来更新图像的旋转角度
def update_rotation_angle(change):
    angle = change.new
    ax.view_init(elev=30, azim=angle)
    with output_widget:
        output_widget.clear_output(wait=True)
        display(fig)

# 将更新函数绑定到旋转小部件的值变化事件
rotation_slider.observe(update_rotation_angle, 'value')

# 创建一个垂直布局小部件来显示图像和旋转控制
vbox = widgets.VBox([output_widget, rotation_slider])

# 显示垂直布局小部件
display(vbox)

"""## Omniglot Dataset

### ArcFace
"""

import torch
import torchvision
import numpy as np
import pytorch_metric_learning
from pytorch_metric_learning import losses
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim
import os
from tqdm import tqdm

# 超参数
batch_size = 256
learning_rate = 0.01
num_epochs = 10
num_classes = 5749 # LFWPeople有5749个类别
embedding_size = 512 # 假设你的网络输出512维的嵌入向量
margin = 28.6 # 这是论文中推荐的值
scale = 64 # 这也是论文中推荐的值


# 定义一个数据转换器，包含上述函数和其他操作
transform = transforms.Compose([
    transforms.ToTensor(), # 将图像转换为张量，并将数值范围从[0,255]变为[0,1]
    transforms.Resize((32, 32)), # 将图像大小调整为32x32
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 将图像归一化，使其数值范围为[-1,1]
])

# 加载数据集，并应用上述转换器
train_dataset = datasets.lfw.LFWPeople(root='data', image_set='funneled', transform=transform, download=True)
test_dataset = datasets.lfw.LFWPeople(root='data', image_set='funneled', transform=transform, split='test', download=True)

# 创建数据加载器，用于分批加载数据
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 获取预训练的ResNet-18模型
model = torchvision.models.resnet18(pretrained=True)

# 修改最后一层全连接层的输出特征数为embedding_size
num_features = model.fc.in_features # 获取全连接层的输入特征数
model.fc = nn.Linear(num_features, embedding_size) # 创建一个新的全连接层，并替换原来的全连接层

# 如果有GPU可用，则将模型移动到GPU上
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# 创建一个ArcFaceLoss对象，并传入相应的参数
loss_func = losses.ArcFaceLoss(num_classes=num_classes, embedding_size=embedding_size, margin=margin, scale=scale)

# 创建一个优化器，并将ArcFaceLoss对象的参数传递给它
optimizer = optim.SGD(list(model.parameters()) + list(loss_func.parameters()), lr=learning_rate)

# 编写训练和测试的循环，用于迭代地更新模型和损失函数的参数，并评估模型的性能

# 训练和测试的循环
for epoch in range(num_epochs):
    # 训练阶段
    model.train() # 设置模型为训练模式
    train_loss = 0.0 # 初始化训练损失
    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}', leave=False)
    for data, labels in progress_bar: # 遍历训练数据
        data = data.to(device) # 将图像移动到设备上
        labels = labels.to(device) # 将标签移动到设备上
        optimizer.zero_grad() # 清空梯度缓存
        embeddings = model(data) # 通过模型得到嵌入向量
        loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
        loss.backward(retain_graph=True) # 反向传播计算梯度，保留计算图
        optimizer.step() # 更新参数
        train_loss += loss.item() * data.size(0) # 累加训练损失
        progress_bar.set_description(f'Epoch {epoch+1}, Train Loss: {train_loss / len(train_dataset):.4f}')

    # 测试阶段
    model.eval() # 设置模型为评估模式
    test_loss = 0.0 # 初始化测试损失
    test_acc = 0.0 # 初始化测试准确率
    with torch.no_grad(): # 不计算梯度，节省内存和时间
        progress_bar = tqdm(test_loader, desc='Testing', leave=False)
        for data, labels in progress_bar: # 遍历测试数据
            data = data.to(device) # 将图像移动到设备上
            labels = labels.to(device) # 将标签移动到设备上
            embeddings = model(data) # 通过模型得到嵌入向量
            loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
            test_loss += loss.item() * data.size(0) # 累加测试损失
            logits = loss_func.get_logits(embeddings) # 通过损失函数得到分类的logits
            preds = torch.argmax(logits, dim=1) # 得到预测的类别
            test_acc += torch.eq(preds, labels).sum().item() # 累加正确预测的数量
            progress_bar.set_description('Testing')

    # 打印每个epoch的结果
    train_loss /= len(train_dataset) # 计算平均训练损失
    test_loss /= len(test_dataset) # 计算平均测试损失
    test_acc /= len(test_dataset) # 计算测试准确率
    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')
print('训练完成')

# 导入matplotlib.pyplot和其他必要的库
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.manifold import TSNE

# 假设你的模型已经训练好了，并且保存在model变量中
# 假设你的测试数据集已经加载好了，并且保存在test_loader变量中

# 创建一个空的列表，用于存储嵌入向量和标签
embeddings = []
labels = []

# 遍历测试数据集，通过模型得到嵌入向量，并将它们和标签添加到列表中
with torch.no_grad(): # 不计算梯度，节省内存和时间
    for data, label in test_loader: # 遍历测试数据
        data = data.to(device) # 将图像移动到设备上
        label = label.to(device) # 将标签移动到设备上
        embedding = model(data) # 通过模型得到嵌入向量
        embeddings.append(embedding) # 将嵌入向量添加到列表中
        labels.append(label) # 将标签添加到列表中

# 将列表转换为numpy数组，并将嵌入向量的维度降为2或3，用于可视化
embeddings = torch.cat(embeddings, dim=0).cpu().numpy() # 将嵌入向量拼接起来，并转换为numpy数组
labels = torch.cat(labels, dim=0).cpu().numpy() # 将标签拼接起来，并转换为numpy数组
tsne = TSNE(n_components=3, perplexity=30, n_iter=1000) # 创建一个TSNE对象，并设置参数
embeddings_3d = tsne.fit_transform(embeddings) # 使用TSNE对象对嵌入向量进行降维，得到三维的坐标

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# 创建一个三维的图形对象，并设置标题和坐标轴标签
fig = plt.figure(figsize=(12, 9), dpi=300)
ax = fig.add_subplot(111, projection='3d')
ax.set_title('LFW × ArcFace')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

# 定义一个色系
cmap = plt.get_cmap('viridis')

# 遍历每个类别，绘制对应颜色的散点图，并添加图例
for i in range(num_classes):
    indices = labels == i  # 找到属于该类别的索引
    x = embeddings_3d[indices, 0]  # 找到对应的x坐标
    y = embeddings_3d[indices, 1]  # 找到对应的y坐标
    z = embeddings_3d[indices, 2]  # 找到对应的z坐标
    color = np.array([cmap(float(i) / num_classes)])  # 将颜色值封装为数组
    ax.scatter(x, y, z, c=color, label=str(i))  # 绘制散点图，并设置颜色和标签

# 创建一个输出小部件
output_widget = widgets.Output()

# 显示图像
with output_widget:
    display(fig)

# 创建一个控制旋转的小部件
rotation_slider = widgets.FloatSlider(min=-180, max=180, value=0, description='Rotation')

# 定义一个函数来更新图像的旋转角度
def update_rotation_angle(change):
    angle = change.new
    ax.view_init(elev=30, azim=angle)
    with output_widget:
        output_widget.clear_output(wait=True)
        display(fig)

# 将更新函数绑定到旋转小部件的值变化事件
rotation_slider.observe(update_rotation_angle, 'value')

# 创建一个垂直布局小部件来显示图像和旋转控制
vbox = widgets.VBox([output_widget, rotation_slider])

# 显示垂直布局小部件
display(vbox)

"""### CosFace"""

import torch
import torchvision
import numpy as np
import pytorch_metric_learning
from pytorch_metric_learning import losses
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim
import os
from tqdm import tqdm

# 超参数
batch_size = 256
learning_rate = 0.01
num_epochs = 10
num_classes = 5749 # LFWPeople有5749个类别
embedding_size = 512 # 假设你的网络输出512维的嵌入向量
margin = 28.6 # 这是论文中推荐的值
scale = 64 # 这也是论文中推荐的值


# 定义一个数据转换器，包含上述函数和其他操作
transform = transforms.Compose([
    transforms.ToTensor(), # 将图像转换为张量，并将数值范围从[0,255]变为[0,1]
    transforms.Resize((32, 32)), # 将图像大小调整为32x32
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 将图像归一化，使其数值范围为[-1,1]
])

# 加载数据集，并应用上述转换器
train_dataset = datasets.lfw.LFWPeople(root='data', image_set='funneled', transform=transform, download=True)
test_dataset = datasets.lfw.LFWPeople(root='data', image_set='funneled', transform=transform, split='test', download=True)

# 创建数据加载器，用于分批加载数据
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 获取预训练的ResNet-18模型
model = torchvision.models.resnet18(pretrained=True)

# 修改最后一层全连接层的输出特征数为embedding_size
num_features = model.fc.in_features # 获取全连接层的输入特征数
model.fc = nn.Linear(num_features, embedding_size) # 创建一个新的全连接层，并替换原来的全连接层

# 如果有GPU可用，则将模型移动到GPU上
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# 创建一个CosFaceLoss对象，并传入相应的参数
loss_func = losses.CosFaceLoss(num_classes=num_classes, embedding_size=embedding_size, margin=margin, scale=scale)

# 创建一个优化器，并将CosFaceLoss对象的参数传递给它
optimizer = optim.SGD(list(model.parameters()) + list(loss_func.parameters()), lr=learning_rate)

# 编写训练和测试的循环，用于迭代地更新模型和损失函数的参数，并评估模型的性能

# 训练和测试的循环
for epoch in range(num_epochs):
    # 训练阶段
    model.train() # 设置模型为训练模式
    train_loss = 0.0 # 初始化训练损失
    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}', leave=False)
    for data, labels in progress_bar: # 遍历训练数据
        data = data.to(device) # 将图像移动到设备上
        labels = labels.to(device) # 将标签移动到设备上
        optimizer.zero_grad() # 清空梯度缓存
        embeddings = model(data) # 通过模型得到嵌入向量
        loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
        loss.backward(retain_graph=True) # 反向传播计算梯度，保留计算图
        optimizer.step() # 更新参数
        train_loss += loss.item() * data.size(0) # 累加训练损失
        progress_bar.set_description(f'Epoch {epoch+1}, Train Loss: {train_loss / len(train_dataset):.4f}')

    # 测试阶段
    model.eval() # 设置模型为评估模式
    test_loss = 0.0 # 初始化测试损失
    test_acc = 0.0 # 初始化测试准确率
    with torch.no_grad(): # 不计算梯度，节省内存和时间
        progress_bar = tqdm(test_loader, desc='Testing', leave=False)
        for data, labels in progress_bar: # 遍历测试数据
            data = data.to(device) # 将图像移动到设备上
            labels = labels.to(device) # 将标签移动到设备上
            embeddings = model(data) # 通过模型得到嵌入向量
            loss = loss_func(embeddings, labels) # 通过损失函数计算损失值
            test_loss += loss.item() * data.size(0) # 累加测试损失
            logits = loss_func.get_logits(embeddings) # 通过损失函数得到分类的logits
            preds = torch.argmax(logits, dim=1) # 得到预测的类别
            test_acc += torch.eq(preds, labels).sum().item() # 累加正确预测的数量
            progress_bar.set_description('Testing')

    # 打印每个epoch的结果
    train_loss /= len(train_dataset) # 计算平均训练损失
    test_loss /= len(test_dataset) # 计算平均测试损失
    test_acc /= len(test_dataset) # 计算测试准确率
    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')
print('训练完成')

# 导入matplotlib.pyplot和其他必要的库
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.manifold import TSNE

# 假设你的模型已经训练好了，并且保存在model变量中
# 假设你的测试数据集已经加载好了，并且保存在test_loader变量中

# 创建一个空的列表，用于存储嵌入向量和标签
embeddings = []
labels = []

# 遍历测试数据集，通过模型得到嵌入向量，并将它们和标签添加到列表中
with torch.no_grad(): # 不计算梯度，节省内存和时间
    for data, label in test_loader: # 遍历测试数据
        data = data.to(device) # 将图像移动到设备上
        label = label.to(device) # 将标签移动到设备上
        embedding = model(data) # 通过模型得到嵌入向量
        embeddings.append(embedding) # 将嵌入向量添加到列表中
        labels.append(label) # 将标签添加到列表中

# 将列表转换为numpy数组，并将嵌入向量的维度降为2或3，用于可视化
embeddings = torch.cat(embeddings, dim=0).cpu().numpy() # 将嵌入向量拼接起来，并转换为numpy数组
labels = torch.cat(labels, dim=0).cpu().numpy() # 将标签拼接起来，并转换为numpy数组
tsne = TSNE(n_components=3, perplexity=30, n_iter=1000) # 创建一个TSNE对象，并设置参数
embeddings_3d = tsne.fit_transform(embeddings) # 使用TSNE对象对嵌入向量进行降维，得到三维的坐标

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# 创建一个三维的图形对象，并设置标题和坐标轴标签
fig = plt.figure(figsize=(12, 9), dpi=300)
ax = fig.add_subplot(111, projection='3d')
ax.set_title('LFW × CosFace')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

# 定义一个色系
cmap = plt.get_cmap('viridis')

# 遍历每个类别，绘制对应颜色的散点图，并添加图例
for i in range(num_classes):
    indices = labels == i  # 找到属于该类别的索引
    x = embeddings_3d[indices, 0]  # 找到对应的x坐标
    y = embeddings_3d[indices, 1]  # 找到对应的y坐标
    z = embeddings_3d[indices, 2]  # 找到对应的z坐标
    color = np.array([cmap(float(i) / num_classes)])  # 将颜色值封装为数组
    ax.scatter(x, y, z, c=color, label=str(i))  # 绘制散点图，并设置颜色和标签

# 创建一个输出小部件
output_widget = widgets.Output()

# 显示图像
with output_widget:
    display(fig)

# 创建一个控制旋转的小部件
rotation_slider = widgets.FloatSlider(min=-180, max=180, value=0, description='Rotation')

# 定义一个函数来更新图像的旋转角度
def update_rotation_angle(change):
    angle = change.new
    ax.view_init(elev=30, azim=angle)
    with output_widget:
        output_widget.clear_output(wait=True)
        display(fig)

# 将更新函数绑定到旋转小部件的值变化事件
rotation_slider.observe(update_rotation_angle, 'value')

# 创建一个垂直布局小部件来显示图像和旋转控制
vbox = widgets.VBox([output_widget, rotation_slider])

# 显示垂直布局小部件
display(vbox)

"""### TripletLoss"""

from pytorch_metric_learning import miners
import torch
import torchvision
import numpy as np
import pytorch_metric_learning
from pytorch_metric_learning import losses
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm

# 创建一个 MultiSimilarityMiner 对象
miner = miners.MultiSimilarityMiner()

# 定义一个数据转换器，包含上述函数和其他操作
transform = transforms.Compose([
    transforms.ToTensor(), # 将图像转换为张量，并将数值范围从[0,255]变为[0,1]
    transforms.Resize((32, 32)), # 将图像大小调整为32x32
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 将图像归一化，使其数值范围为[-1,1]
])

# 加载数据集，并应用上述转换器
train_dataset = datasets.lfw.LFWPeople(root='data', image_set='funneled', transform=transform, download=True)
test_dataset = datasets.lfw.LFWPeople(root='data', image_set='funneled', transform=transform, split='test', download=True)

# 创建数据加载器，用于分批加载数据
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# 获取预训练的ResNet-18模型
model = torchvision.models.resnet18(pretrained=False)

# 修改最后一层全连接层的输出特征数为embedding_size
num_features = model.fc.in_features # 获取全连接层的输入特征数
model.fc = nn.Sequential(
    nn.Linear(num_features, embedding_size),
    nn.ReLU(),
    nn.Linear(embedding_size, num_classes)
)

# 如果有GPU可用，则将模型移动到GPU上
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# 创建一个 TripletMarginLoss 对象
loss_func = losses.TripletMarginLoss(margin=0.05)

# 创建一个优化器，并将TripletMarginLoss对象的参数传递给它
optimizer = optim.SGD(list(model.parameters()) + list(loss_func.parameters()), lr=learning_rate)

for epoch in range(num_epochs):
    # 训练阶段
    model.train()
    train_loss = 0.0
    for data, labels in tqdm(train_loader, desc="Training"):
        data = data.to(device)
        labels = labels.to(device)
        optimizer.zero_grad()
        embeddings = model(data)
        
        # 调用 miner 得到 indices_tuple
        indices_tuple = miner(embeddings, labels)
        
        # 将 embeddings 和 indices_tuple 传入 loss_func
        loss = loss_func(embeddings, labels, indices_tuple)
        
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * data.size(0)

    # 测试阶段
    model.eval()
    test_loss = 0.0
    test_acc = 0.0
    with torch.no_grad():
        for data, labels in tqdm(test_loader, desc="Testing"):
            data = data.to(device)
            labels = labels.to(device)
            outputs = model(data) # 使用模型的输出作为预测结果
            embeddings = outputs[:, :-num_classes] # 获取嵌入向量
            
            indices_tuple = miner(embeddings, labels)
            
            loss = loss_func(embeddings, labels, indices_tuple)
            
            test_loss += loss.item() * data.size(0)
            preds = torch.argmax(outputs, dim=1) # 使用模型的输出来获取预测的类别
            test_acc += torch.sum(preds == labels).item()

    train_loss /= len(train_dataset)
    test_loss /= len(test_dataset)
    test_acc /= len(test_dataset)
    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')

# 导入matplotlib.pyplot和其他必要的库
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from sklearn.manifold import TSNE

# 假设你的模型已经训练好了，并且保存在model变量中
# 假设你的测试数据集已经加载好了，并且保存在test_loader变量中

# 创建一个空的列表，用于存储嵌入向量和标签
embeddings = []
labels = []

# 遍历测试数据集，通过模型得到嵌入向量，并将它们和标签添加到列表中
with torch.no_grad(): # 不计算梯度，节省内存和时间
    for data, label in test_loader: # 遍历测试数据
        data = data.to(device) # 将图像移动到设备上
        label = label.to(device) # 将标签移动到设备上
        embedding = model(data) # 通过模型得到嵌入向量
        embeddings.append(embedding) # 将嵌入向量添加到列表中
        labels.append(label) # 将标签添加到列表中

# 将列表转换为numpy数组，并将嵌入向量的维度降为2或3，用于可视化
embeddings = torch.cat(embeddings, dim=0).cpu().numpy() # 将嵌入向量拼接起来，并转换为numpy数组
labels = torch.cat(labels, dim=0).cpu().numpy() # 将标签拼接起来，并转换为numpy数组
tsne = TSNE(n_components=3, perplexity=30, n_iter=1000) # 创建一个TSNE对象，并设置参数
embeddings_3d = tsne.fit_transform(embeddings) # 使用TSNE对象对嵌入向量进行降维，得到三维的坐标

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# 创建一个三维的图形对象，并设置标题和坐标轴标签
fig = plt.figure(figsize=(12, 9), dpi=300)
ax = fig.add_subplot(111, projection='3d')
ax.set_title('LFW × TripletMarginLosse')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

# 定义一个色系
cmap = plt.get_cmap('viridis')

# 遍历每个类别，绘制对应颜色的散点图，并添加图例
for i in range(num_classes):
    indices = labels == i  # 找到属于该类别的索引
    x = embeddings_3d[indices, 0]  # 找到对应的x坐标
    y = embeddings_3d[indices, 1]  # 找到对应的y坐标
    z = embeddings_3d[indices, 2]  # 找到对应的z坐标
    color = np.array([cmap(float(i) / num_classes)])  # 将颜色值封装为数组
    ax.scatter(x, y, z, c=color, label=str(i))  # 绘制散点图，并设置颜色和标签

# 创建一个输出小部件
output_widget = widgets.Output()

# 显示图像
with output_widget:
    display(fig)

# 创建一个控制旋转的小部件
rotation_slider = widgets.FloatSlider(min=-180, max=180, value=0, description='Rotation')

# 定义一个函数来更新图像的旋转角度
def update_rotation_angle(change):
    angle = change.new
    ax.view_init(elev=30, azim=angle)
    with output_widget:
        output_widget.clear_output(wait=True)
        display(fig)

# 将更新函数绑定到旋转小部件的值变化事件
rotation_slider.observe(update_rotation_angle, 'value')

# 创建一个垂直布局小部件来显示图像和旋转控制
vbox = widgets.VBox([output_widget, rotation_slider])

# 显示垂直布局小部件
display(vbox)

